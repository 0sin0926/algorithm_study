### 1. 문제 이해
- n장의 카드 중 2개를 뽑아 더한 후, 그 카드 2개의 값을 합으로 덮어씀 => m번 반복
- 위 과정 후 모든 카드의 합이 최소가 되게

### 2. 입출력 조건
- 1초 / 512MB
- n <= 1000, m <= 15*n (15,000)
- ai의 값 <= 1,000,000

### 3. 문제 풀이
- 그리디 -> 작은 거 기준 정렬
- 처음엔 단순히 합을 구하고 그걸 맨 뒤로 넣어버렸는데, 매 번 최선의 선택(가장 작은 거)을 해야되기 때문에 pq를 써서 합을 넣을 때 매번 정렬해야함
- pq로 O(lgN)에 넣음, 총 O(NlgN)에 끝내기 가능

### 4. 구현
- 합을 구하면서 계속 값이 커지다 보면 최대 (1,000,000*2) * 15,000 이 넘을 수 있기 때문에 값을 저장하는 변수들을 모두 longlong으로 선언
- 나머지는 단순 구현
